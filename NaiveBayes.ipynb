{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not installed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dmc\n",
    "from process import processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = processed_data()\n",
    "train_ids, test_ids = dmc.loading.load_ids('rawMirrored')\n",
    "train, test = dmc.preprocessing.split_train_test(data, train_ids, test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and boost naive bayes on mirrored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "offset = len(train)\n",
    "X, y = dmc.transformation.transform(data, ignore_features=['returnQuantity', 'orderID', 'orderDate', 'customerID'],\n",
    "                                    binary_target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fts = dmc.transformation.transform_feature_matrix_ph(data, ignore_features=['returnQuantity', 'orderID', 'orderDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dmc.classifiers import NaiveBayes, NaiveBayesM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = X[:offset], y[:offset]\n",
    "test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standard naive bayes\n",
    "clf = NaiveBayes(train[0], train[1])\n",
    "res = clf(test[0])\n",
    "precision = dmc.evaluation.precision(res, test[1])\n",
    "print(precision, ' using ', str(NaiveBayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_evaluation = dmc.evaluation.evaluate_features_leaving_one_out(train[0], train[1], test[0], test[1],\n",
    "                                                                      fts, NaiveBayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# boosted with target set knowledge\n",
    "negative_features = set(feature_evaluation.index[feature_evaluation.decrement < 0])\n",
    "fts_series = pd.Series(fts).apply(lambda x: False if x in negative_features else True)\n",
    "fts_mask = np.array(fts_series)\n",
    "X_tr, X_cl = train[0].T[fts_mask].T, test[0].T[fts_mask].T\n",
    "print('Train and Evaluate')\n",
    "clf = NaiveBayes(X_tr, train[1])\n",
    "prec = dmc.evaluation.precision(test[1], clf(X_cl))\n",
    "print(prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use ensemble and optimize each splits for used features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# allocate memory\n",
    "data = train_ids = test_ids = None\n",
    "####\n",
    "ensemble = dmc.ensemble.Ensemble(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2082 unknown_articleID-unknown_customerID-unknown_voucherID-known_productGroup\n",
      "14 unknown_articleID-unknown_customerID-known_voucherID-unknown_productGroup\n",
      "22160 unknown_articleID-unknown_customerID-known_voucherID-known_productGroup\n",
      "3239 unknown_articleID-known_customerID-unknown_voucherID-known_productGroup\n",
      "12 unknown_articleID-known_customerID-known_voucherID-unknown_productGroup\n",
      "62265 unknown_articleID-known_customerID-known_voucherID-known_productGroup\n",
      "4189 known_articleID-unknown_customerID-unknown_voucherID-known_productGroup\n",
      "42844 known_articleID-unknown_customerID-known_voucherID-known_productGroup\n",
      "6496 known_articleID-known_customerID-unknown_voucherID-known_productGroup\n",
      "93197 known_articleID-known_customerID-known_voucherID-known_productGroup\n"
     ]
    }
   ],
   "source": [
    "for split in ensemble.splits:\n",
    "    print(len(ensemble.splits[split][1]), split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print splits and names to know where to not drop customer for naive bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splits = len(ensemble.splits)\n",
    "scalers = [dmc.transformation.scale_features] * splits\n",
    "ignore = ([None] * 3 + \n",
    "          [['returnQuantity', 'orderID', 'orderDate']] * 3 + \n",
    "          [None] * 2 + \n",
    "          [['returnQuantity', 'orderID', 'orderDate']] * 2)\n",
    "ensemble.transform(scalers=scalers, ignore_features=ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown_articleID-unknown_customerID-unknown_voucherID-known_productGroup 0.6748318924111432 2082\n",
      "unknown_articleID-unknown_customerID-known_voucherID-unknown_productGroup 0.8571428571428572 14\n",
      "unknown_articleID-unknown_customerID-known_voucherID-known_productGroup 0.645216606498195 22160\n",
      "unknown_articleID-known_customerID-unknown_voucherID-known_productGroup 0.6779870330348874 3239\n",
      "unknown_articleID-known_customerID-known_voucherID-unknown_productGroup 0.6666666666666667 12\n",
      "unknown_articleID-known_customerID-known_voucherID-known_productGroup 0.6542038063117321 62265\n",
      "known_articleID-unknown_customerID-unknown_voucherID-known_productGroup 0.6116018142754834 4189\n",
      "known_articleID-unknown_customerID-known_voucherID-known_productGroup 0.6478620110167118 42844\n",
      "known_articleID-known_customerID-unknown_voucherID-known_productGroup 0.6608682266009852 6496\n",
      "known_articleID-known_customerID-known_voucherID-known_productGroup 0.6649355665954912 93197\n"
     ]
    }
   ],
   "source": [
    "for k in ensemble.splits:\n",
    "    Xt, yt = ensemble.splits[k]['train'][0], ensemble.splits[k]['train'][1]\n",
    "    Xe, ye = ensemble.splits[k]['test'][0], ensemble.splits[k]['test'][1]\n",
    "    fts, clf = ensemble.splits[k]['features'], dmc.classifiers.NaiveBayes\n",
    "    feature_evaluation = dmc.evaluation.evaluate_features_leaving_one_out(Xt, yt, Xe, ye, fts, clf)\n",
    "    negative_features = set(feature_evaluation.index[feature_evaluation.decrement < 0])\n",
    "    fts_mask = np.array(pd.Series(fts).apply(lambda x: False if x in negative_features else True))\n",
    "    Xt, Xe = Xt.T[fts_mask].T, Xe.T[fts_mask].T\n",
    "    clf = clf(Xt, yt)\n",
    "    prec = dmc.evaluation.precision(ye, clf(Xe))\n",
    "    print(k, prec, len(ye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown_articleID-unknown_customerID-unknown_voucherID-known_productGroup 0.6805955811719501 2082\n",
      "unknown_articleID-unknown_customerID-known_voucherID-unknown_productGroup 0.8571428571428572 14\n",
      "unknown_articleID-unknown_customerID-known_voucherID-known_productGroup 0.6523014440433212 22160\n",
      "unknown_articleID-known_customerID-unknown_voucherID-known_productGroup 0.657919110836678 3239\n",
      "unknown_articleID-known_customerID-known_voucherID-unknown_productGroup 0.6666666666666667 12\n",
      "unknown_articleID-known_customerID-known_voucherID-known_productGroup 0.6497550790974063 62265\n",
      "known_articleID-unknown_customerID-unknown_voucherID-known_productGroup 0.6619718309859155 4189\n",
      "known_articleID-unknown_customerID-known_voucherID-known_productGroup 0.6553076276724863 42844\n",
      "known_articleID-known_customerID-unknown_voucherID-known_productGroup 0.6579433497536946 6496\n",
      "known_articleID-known_customerID-known_voucherID-known_productGroup 0.6523600545081923 93197\n"
     ]
    }
   ],
   "source": [
    "for k in ensemble.splits:\n",
    "    Xt, yt = ensemble.splits[k]['train'][0], ensemble.splits[k]['train'][1]\n",
    "    Xe, ye = ensemble.splits[k]['test'][0], ensemble.splits[k]['test'][1]\n",
    "    fts, clf = ensemble.splits[k]['features'], dmc.classifiers.NaiveBayes\n",
    "    clf = clf(Xt, yt)\n",
    "    prec = dmc.evaluation.precision(ye, clf(Xe))\n",
    "    print(k, prec, len(ye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/anaconda3/lib/python3.5/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/alex/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/alex/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/alex/anaconda3/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/alex/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/alex/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/alex/anaconda3/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-2410e1c1eaba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdmc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mForest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mprec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdmc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mye\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mye\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/alex/Documents/run-dmc/dmc/classifiers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/alex/Documents/run-dmc/dmc/classifiers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/alex/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 290\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/alex/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    810\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/alex/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m                 \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m                 \u001b[1;31m# Stop dispatching any new job in the async callback thread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/alex/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/alex/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/alex/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/alex/anaconda3/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in ensemble.splits:\n",
    "    Xt, yt = ensemble.splits[k]['train'][0], ensemble.splits[k]['train'][1]\n",
    "    Xe, ye = ensemble.splits[k]['test'][0], ensemble.splits[k]['test'][1]\n",
    "    fts, clf = ensemble.splits[k]['features'], dmc.classifiers.Forest\n",
    "    clf = clf(Xt, yt)\n",
    "    prec = dmc.evaluation.precision(ye, clf(Xe))\n",
    "    print(k, prec, len(ye))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result for optimized leaving one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65639032888227389"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = [(0.6748318924111432, 2082), (0.8571428571428572, 14), (0.645216606498195, 22160), (0.6779870330348874, 3239),\n",
    " (0.6666666666666667, 12), (0.6542038063117321, 62265), (0.6116018142754834, 4189), (0.6478620110167118, 42844), \n",
    " (0.6608682266009852, 6496), (0.6649355665954912, 93197)]\n",
    "prec1, size1 = np.array([e[0] for e in res1]), np.array([e[1] for e in res1])\n",
    "np.sum(np.multiply(prec1, size1)/len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result for unoptimized naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65286387199891749"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = [(0.6805955811719501, 2082), (0.8571428571428572, 14), (0.6523014440433212, 22160), (0.657919110836678, 3239),\n",
    "       (0.6666666666666667, 12), (0.6497550790974063, 62265), (0.6619718309859155, 4189), (0.6553076276724863, 42844),\n",
    "       (0.6579433497536946, 6496), (0.6523600545081923, 93197)]\n",
    "prec2, size2 = np.array([e[0] for e in res2]), np.array([e[1] for e in res2])\n",
    "np.sum(np.multiply(prec2, size2)/len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal results of both combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65934595641400762"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precs = np.vstack([prec1, prec2])\n",
    "optim_precs = np.max(precs, axis=0)\n",
    "np.sum(np.multiply(optim_precs, size2)/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.68059558,  0.85714286,  0.65230144,  0.67798703,  0.66666667,\n",
       "        0.65420381,  0.66197183,  0.65530763,  0.66086823,  0.66493557])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_precs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate final precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifiers = [dmc.classifiers.DecisionTree, dmc.classifiers.NaiveBayes, dmc.classifiers.Forest]\n",
    "Xn = X[y > 0]\n",
    "yn = y[y > 0]\n",
    "for clf in classifiers:\n",
    "    c = clf(Xn[:900000], yn[:900000])\n",
    "    pred = c(Xn[900000:])\n",
    "    print('precision', dmc.evaluation.dmc_cost_relative(pred, yn[900000:]), 'with', clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on Train:\n",
    "```\n",
    "precision 8.27814569536e-07 with <class 'dmc.classifiers.DecisionTree'>\n",
    "precision 0.00368625827815 with <class 'dmc.classifiers.NaiveBayes'>\n",
    "precision 8.27814569536e-07 with <class 'dmc.classifiers.Forest'>\n",
    "```\n",
    "\n",
    "Test on 25%, Train on 75%:\n",
    "```\n",
    "precision 0.00435064935065 with <class 'dmc.classifiers.DecisionTree'>\n",
    "precision 0.00391233766234 with <class 'dmc.classifiers.NaiveBayes'>\n",
    "precision 0.00393181818182 with <class 'dmc.classifiers.Forest'>\n",
    "```\n",
    "\n",
    "Evaluation of rule approach versus classifier approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def switch_predictor(quantity):\n",
    "    if quantity == 1:\n",
    "        return 1\n",
    "    elif quantity == 2:\n",
    "        return 1\n",
    "    elif quantity == 3:\n",
    "        return 2\n",
    "    elif quantity == 4:\n",
    "        return 2\n",
    "    elif quantity == 5:\n",
    "        return 3\n",
    "    print('FAIL')\n",
    "    return None\n",
    "\n",
    "evalframe = test[test.returnQuantity > 0]\n",
    "pred = evalframe.quantity.apply(switch_predictor)\n",
    "print('precision', dmc.evaluation.dmc_cost_relative(pred, evalframe.returnQuantity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting using the above switch is the most precise way if one does not want to train a specially optimized regressor/classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
