{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not installed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dmc\n",
    "from process import processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = processed_data()\n",
    "train_ids, test_ids = dmc.loading.load_ids('rawMirrored')\n",
    "train, test = dmc.preprocessing.split_train_test(data, train_ids, test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full ensemble to classify and rerun on different data after learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor e in ensemble.splits:\\n    ensemble.splits[e] = {**ensemble.splits[e], **params[e]}\\nprint(ensemble.splits)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forest, Network, Bayes, SVM = dmc.classifiers.Forest, dmc.classifiers.TheanoNeuralNetwork, dmc.classifiers.NaiveBayes, dmc.classifiers.SVM\n",
    "Tree = dmc.classifiers.DecisionTree\n",
    "raw_scaler, scaler, no_scaler = dmc.transformation.scale_raw_features, dmc.transformation.scale_features, None\n",
    "no_sample = None\n",
    "params = {\n",
    "    'uuuu': {'sample': 20000, 'scaler': None, 'ignore_features': None, 'classifier': Forest},\n",
    "    'uuuk': {'sample': 20000, 'scaler': None, 'ignore_features': None, 'classifier': Forest},\n",
    "    'uuku': {'sample': 20000, 'scaler': None, 'ignore_features': None, 'classifier': Forest},\n",
    "    'uukk': {'sample': 20000, 'scaler': None, 'ignore_features': None, 'classifier': Forest}, # Theano\n",
    "    'ukuu': {'sample': 20000, 'scaler': None, 'ignore_features': None, 'classifier': Forest},\n",
    "    'ukuk': {'sample': 20000, 'scaler': None, 'ignore_features': None, 'classifier': Forest},\n",
    "    'ukku': {'sample': 20000, 'scaler': None, 'ignore_features': None, 'classifier': Forest},\n",
    "    'ukkk': {'sample': 200000, 'scaler': None, 'ignore_features': None, 'classifier': Forest},\n",
    "    'kuuu': {'sample': 20000, 'scaler': None, 'ignore_features': None, 'classifier': Forest},\n",
    "    'kuuk': {'sample': 20000, 'scaler': None, 'ignore_features': None, 'classifier': Forest}, # Theano\n",
    "    'kuku': {'sample': 20000, 'scaler': None, 'ignore_features': None, 'classifier': Forest}, \n",
    "    'kukk': {'sample': 200000, 'scaler': None, 'ignore_features': None, 'classifier': Forest}, # Theano\n",
    "    'kkuu': {'sample': 200000, 'scaler': None, 'ignore_features': None, 'classifier': Forest},\n",
    "    'kkuk': {'sample': 200000, 'scaler': None, 'ignore_features': None, 'classifier': Forest},\n",
    "    'kkku': {'sample': 20000, 'scaler': None, 'ignore_features': None, 'classifier': Forest},\n",
    "    'kkkk': {'sample': 200000, 'scaler': None, 'ignore_features': None, 'classifier': Forest}\n",
    "}\n",
    "\"\"\"\n",
    "for e in ensemble.splits:\n",
    "    ensemble.splits[e] = {**ensemble.splits[e], **params[e]}\n",
    "print(ensemble.splits)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# allocate memory\n",
    "data = train_ids = test_ids = None\n",
    "####\n",
    "ensemble = dmc.ensemble.ECEnsemble(train, test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ensemble.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uuuk precision 0.6738712776176753 size 2082\n",
      "uuku precision 0.8571428571428572 size 14\n",
      "uukk precision 0.6620036101083033 size 22160\n",
      "ukuk precision 0.6591540598950294 size 3239\n",
      "ukku precision 0.6666666666666667 size 12\n",
      "ukkk precision 0.6458202842688509 size 62265\n",
      "kuuk precision 0.6667462401527811 size 4189\n",
      "kukk precision 0.6615628792829802 size 42844\n",
      "kkuk precision 0.645628078817734 size 6496\n",
      "kkkk precision 0.6456538300589074 size 93197\n",
      "OVERALL: 0.650931508935\n"
     ]
    }
   ],
   "source": [
    "ensemble.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for split in ensemble.splits:\n",
    "    print(len(ensemble.splits[split][1]), split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print splits and names to know where to not drop customer for naive bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "```\n",
    "known_articleID-unknown_customerID-unknown_voucherID-known_productGroup : size  4189  prec  0.659823346860826\n",
    "--------------------------------------\n",
    "known_articleID-known_customerID-known_voucherID-known_productGroup : size  93197  prec  0.6745603399251049\n",
    "--------------------------------------\n",
    "unknown_articleID-known_customerID-known_voucherID-known_productGroup : size  62265  prec  0.6728338552959126\n",
    "--------------------------------------\n",
    "unknown_articleID-unknown_customerID-known_voucherID-unknown_productGroup : size  14  prec  0.8571428571428572\n",
    "--------------------------------------\n",
    "known_articleID-known_customerID-unknown_voucherID-known_productGroup : size  6496  prec  0.6657943349753694\n",
    "--------------------------------------\n",
    "unknown_articleID-unknown_customerID-known_voucherID-known_productGroup : size  22160  prec  0.6546931407942238\n",
    "--------------------------------------\n",
    "unknown_articleID-unknown_customerID-unknown_voucherID-known_productGroup : size  2082  prec  0.6652257444764649\n",
    "--------------------------------------\n",
    "unknown_articleID-known_customerID-known_voucherID-unknown_productGroup : size  12  prec  0.6666666666666667\n",
    "--------------------------------------\n",
    "known_articleID-unknown_customerID-known_voucherID-known_productGroup : size  42844  prec  0.6607459620950424\n",
    "--------------------------------------\n",
    "unknown_articleID-known_customerID-unknown_voucherID-known_productGroup : size  3239  prec  0.6687249150972523\n",
    "--------------------------------------\n",
    "Overall : 0.6690881106816972 78260\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with 50k sample\n",
    "```\n",
    "\n",
    "unknown_articleID-unknown_customerID-unknown_voucherID-known_productGroup 0.6714697406340058 2082\n",
    "unknown_articleID-unknown_customerID-known_voucherID-unknown_productGroup 0.8571428571428572 14\n",
    "unknown_articleID-unknown_customerID-known_voucherID-known_productGroup 0.6607851985559567 22160\n",
    "unknown_articleID-known_customerID-unknown_voucherID-known_productGroup 0.6644025933930225 3239\n",
    "unknown_articleID-known_customerID-known_voucherID-unknown_productGroup 0.6666666666666667 12\n",
    "unknown_articleID-known_customerID-known_voucherID-known_productGroup 0.6448727214325864 62265\n",
    "known_articleID-unknown_customerID-unknown_voucherID-known_productGroup 0.6719980902363333 4189\n",
    "known_articleID-unknown_customerID-known_voucherID-known_productGroup 0.6569881430305293 42844\n",
    "known_articleID-known_customerID-unknown_voucherID-known_productGroup 0.6366995073891626 6496\n",
    "known_articleID-known_customerID-known_voucherID-known_productGroup 0.6434649183986609 93197\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for split in ensemble.splits:\n",
    "    ensemble.splits[split] = (shuffle(ensemble.splits[split][0])[:200000], ensemble.splits[split][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ensemble.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splits = len(ensemble.splits)\n",
    "scalers = [dmc.transformation.scale_raw_features] * splits\n",
    "ignore = [None] * splits\n",
    "ensemble.transform(scalers=scalers, ignore_features=ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for k in ensemble.splits:\n",
    "    if len(ensemble.splits[k]['test'][1]) < 3000:\n",
    "        continue\n",
    "    Xt, yt = ensemble.splits[k]['train'][0], ensemble.splits[k]['train'][1]\n",
    "    Xe, ye = ensemble.splits[k]['test'][0], ensemble.splits[k]['test'][1]\n",
    "    fts, clf = ensemble.splits[k]['features'], dmc.classifiers.TheanoNeuralNetwork\n",
    "    clf = clf(Xt, yt)\n",
    "    prec = dmc.evaluation.precision(ye, clf(Xe))\n",
    "    res.append((k, prec, len(ye)))\n",
    "    print(k, prec, len(ye), clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resF = []\n",
    "for k in ensemble.splits:\n",
    "    if len(ensemble.splits[k]['test'][1]) < 3000:\n",
    "        continue\n",
    "    Xt, yt = ensemble.splits[k]['train'][0], ensemble.splits[k]['train'][1]\n",
    "    Xe, ye = ensemble.splits[k]['test'][0], ensemble.splits[k]['test'][1]\n",
    "    fts, clf = ensemble.splits[k]['features'], dmc.classifiers.Forest\n",
    "    clf = clf(Xt, yt)\n",
    "    prec = dmc.evaluation.precision(ye, clf(Xe))\n",
    "    resF.append((k, prec, len(ye)))\n",
    "    print(k, prec, len(ye), clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in ensemble.splits:\n",
    "    Xt, yt = ensemble.splits[k]['train'][0], ensemble.splits[k]['train'][1]\n",
    "    Xe, ye = ensemble.splits[k]['test'][0], ensemble.splits[k]['test'][1]\n",
    "    fts, clf = ensemble.splits[k]['features'], dmc.classifiers.NaiveBayes\n",
    "    clf = clf(Xt, yt)\n",
    "    prec = dmc.evaluation.precision(ye, clf(Xe))\n",
    "    print(k, prec, len(ye), clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Forest, Network, Bayes, SVM = dmc.classifiers.Forest, dmc.classifiers.TheanoNeuralNetwork, dmc.classifiers.Bayes, dmc.classifiers.SVM\n",
    "raw_scaler, no_scaler = dmc.transformation.scale_raw_features, None\n",
    "no_sample = None\n",
    "params = {\n",
    "    'uuuu': \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
